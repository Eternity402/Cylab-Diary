{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One to Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNa9Z4+vw35J2BQojwmtDnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eternity402/Cylab-Diary/blob/master/One_to_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9vnfBhmXk0L",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "# 원래 만들어 두었던 TF Skeleton Code\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def build_MLP(N_layer, L_nodes, session):\n",
        "    sess = session\n",
        "\n",
        "    input_size = L_nodes[0]\n",
        "    output_size = L_nodes[-1]\n",
        "\n",
        "    PH_x = tf.placeholder(dtype = tf.float32, shape = [None, input_size])\n",
        "    PH_y = tf.placeholder(dtype = tf.float32, shape = [None, output_size])\n",
        "    \n",
        "    Layers = {}\n",
        "    Layers[0] = PH_x\n",
        "    \n",
        "    for i in range(N_layer):\n",
        "        Layers[i+1] = tf.layers.dense(Layers[i],L_nodes[i+1],activation = tf.nn.leaky_relu)\n",
        "    \n",
        "    Output = Layers[N_layer]\n",
        "\n",
        "    loss = tf.reduce_mean(tf.square(PH_y - Output))\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    return PH_x, PH_y, Layers, loss, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SIKDRDsgr8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cd31728-3d60-4ee9-b908-1da35593ceea"
      },
      "source": [
        "# 잘 작동하는지 시험해보기!\n",
        "\n",
        "nodes = [4,16,8,1]\n",
        "sess = tf.Session()\n",
        "x,y,layers,loss,optimizer = build_MLP(3,nodes,sess)\n",
        "number = np.zeros((10000,4))\n",
        "value = np.zeros((10000,1))\n",
        "for i in range(10000):\n",
        "    number[i,0] = random.randrange(1,10)\n",
        "    number[i,1] = random.randrange(1,5)\n",
        "    number[i,2] = random.randrange(1,15)\n",
        "    number[i,3] = random.randrange(1,30)\n",
        "    value[i,0] = np.sum(number[i,:])\n",
        "for i in range(3000):\n",
        "    sess.run(optimizer, feed_dict = {x:number,y:value})\n",
        "print(sess.run(layers[3], feed_dict={x:[[2,2,2,2]]}))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.040109]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o5oGiE3YBuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TF 2.0 버전으로 최신화한 TF Skeleton Code\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def build_MLP_N(N_layer, L_nodes):\n",
        "  model = tf.keras.models.Sequential([])\n",
        "  for i in range(N_layer):\n",
        "    model.add(tf.keras.layers.Dense(L_nodes[i+1],activation =tf.nn.leaky_relu))\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.mean_squared_error)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvmPC9QsdPp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "e8554cb7-34f9-4942-b5a9-671fec9a2582"
      },
      "source": [
        "# 잘 작동하는지 시험해보기! - 2\n",
        "\n",
        "nodes = [4,16,8,1]\n",
        "model = build_MLP_N(3,nodes)\n",
        "number = np.zeros((10000,4))\n",
        "value = np.zeros((10000,1))\n",
        "for i in range(10000):\n",
        "    number[i,0] = random.randrange(1,10)\n",
        "    number[i,1] = random.randrange(1,5)\n",
        "    number[i,2] = random.randrange(1,15)\n",
        "    number[i,3] = random.randrange(1,30)\n",
        "    value[i,0] = np.sum(number[i,:])\n",
        "for i in range(20):\n",
        "    #sess.run(optimizer, feed_dict = {x:number,y:value})\n",
        "    model.fit(number,value,epochs=1)\n",
        "#print(sess.run(layers[3], feed_dict={x:[[2,2,2,2]]}))\n",
        "model.predict(np.expand_dims([2,2,2,2],axis=0))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 2s 153us/sample - loss: 64.6439\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.2141\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0851\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0521\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0396\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0310\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0241\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.0182\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0138\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0105\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0081\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0062\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0049\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0039\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0031\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0025\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 44us/sample - loss: 0.0020\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0016\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0013\n",
            "Train on 10000 samples\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.031967]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}
